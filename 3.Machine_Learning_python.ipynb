{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>                             Essentials of Machine Learning Algorithms (with Python)</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning is the subfield of computer science that \"gives computers the ability to learn without being explicitly programmed\" (Arthur Samuel, 1959). Evolved from the study of pattern recognition and computational learning theory in artificial intelligence,machine learning explores the study and construction of algorithms that can learn from and make predictions on data – such algorithms overcome following strictly static program instructions by making data-driven predictions or decisions;through building a model from sample inputs. Machine learning is employed in a range of computing tasks where designing and programming explicit algorithms is unfeasible; example applications include spam filtering, optical character recognition (OCR),search engines and computer vision.\n",
    "\n",
    "Machine learning is closely related to (and often overlaps with) computational statistics, which also focuses in prediction-making through the use of computers. It has strong ties to mathematical optimization, which delivers methods, theory and application domains to the field. Machine learning is sometimes conflated with data mining, where the latter subfield focuses more on exploratory data analysis and is known as unsupervised learning.\n",
    "\n",
    "Within the field of data analytics, machine learning is a method used to devise complex models and algorithms that lend themselves to prediction; in commercial use, this is known as predictive analytics. These analytical models allow researchers, data scientists, engineers, and analysts to \"produce reliable, repeatable decisions and results\" and uncover \"hidden insights\" through learning from historical relationships and trends in the data.\n",
    "\n",
    "To read more go to: https://en.wikipedia.org/wiki/Machine_learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Why is machine learning important?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resurging interest in machine learning is due to the same factors that have made data mining and Bayesian analysis more popular than ever. Things like growing volumes and varieties of available data, computational processing that is cheaper and more powerful, and affordable data storage.\n",
    "\n",
    "All of these things mean it's possible to quickly and automatically produce models that can analyze bigger, more complex data and deliver faster, more accurate results – even on a very large scale. And by building precise models, an organization has a better chance of identifying profitable opportunities – or avoiding unknown risks.\n",
    "\n",
    "<h5>Broadly, there are 3 types of Machine Learning Algorithms:</h5>\n",
    "\n",
    "<h5>Supervised Learning:</h5>\n",
    "\n",
    "<b>How it works</b>: This algorithm consist of a target / outcome variable (or dependent variable) which is to be predicted from a given set of predictors (independent variables). Using these set of variables, we generate a function that map inputs to desired outputs. The training process continues until the model achieves a desired level of accuracy on the training data. Examples of Supervised Learning: Regression, Decision Tree, Random Forest, KNN, Logistic Regression etc.\n",
    "\n",
    " \n",
    "<h5>Unsupervised Learning:</h5>\n",
    "\n",
    "<b>How it works</b>: In this algorithm, we do not have any target or outcome variable to predict / estimate.  It is used for clustering population in different groups, which is widely used for segmenting customers in different groups for specific intervention. Examples of Unsupervised Learning: Apriori algorithm, K-means.\n",
    "\n",
    " \n",
    "<h5>Reinforcement Learning:</h5>\n",
    "\n",
    "<b>How it works</b>:  Using this algorithm, the machine is trained to make specific decisions. It works this way: the machine is exposed to an environment where it trains itself continually using trial and error. This machine learns from past experience and tries to capture the best possible knowledge to make accurate business decisions. Example of Reinforcement Learning: Markov Decision Process\n",
    "\n",
    "To read more go to : https://www.analyticsvidhya.com/blog/2015/08/common-machine-learning-algorithms/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>List of Common Machine Learning Algorithms:</h3>\n",
    "\n",
    "Here is the list of commonly used machine learning algorithms. These algorithms can be applied to almost any data problem:\n",
    "\n",
    "<ol><li> Linear Regression</li>\n",
    "<li>Logistic Regression</li>\n",
    "<li>Decision Tree</li>\n",
    "<li>SVM</li>\n",
    "<li>Naive Bayes</li>\n",
    "<li>KNN</li>\n",
    "<li>K-Means</li>\n",
    "<li>Random Forest</li>\n",
    "<li>Dimensionality Reduction Algorithms</li>\n",
    "<li>Gradient Boost & Adaboost</li></ol>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Choose The Best Machine Learning Model</h3>\n",
    "\n",
    "How do you choose the best model for your problem?\n",
    "\n",
    "When you work on a machine learning project, you often end up with multiple good models to choose from. Each model will have different performance characteristics.\n",
    "\n",
    "Using resampling methods like cross validation, you can get an estimate for how accurate each model may be on unseen data. You need to be able to use these estimates to choose one or two best models from the suite of models that you have created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Compare Machine Learning Models Carefully</h3>\n",
    "\n",
    "When you have a new dataset, it is a good idea to visualize the data using different techniques in order to look at the data from different perspectives.\n",
    "\n",
    "The same idea applies to model selection. You should use a number of different ways of looking at the estimated accuracy of your machine learning algorithms in order to choose the one or two to finalize.\n",
    "\n",
    "A way to do this is to use different visualization methods to show the average accuracy, variance and other properties of the distribution of model accuracies.\n",
    "\n",
    "In the next section you will discover exactly how you can implement various algorithms in Python and judge their performance based on accuracy <b>(with scikit-learn)</b>\n",
    "\n",
    "NOTE:<b>Scikit-learn</b> (formerly scikits.learn) is a free software machine learning library for the Python programming language.It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy.  know m\n",
    "To know more about Scikit-learn follow the link : http://scikit-learn.org/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Packages needed to be imported</h3><pre>\n",
    "1.scikit-learn\n",
    "2.numpy</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Installing scikit-learn and numpy</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uncomment to install\n",
    "# !pip install -U scikit-learn\n",
    "# !pip install -U numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Cross Validation: </h3>\n",
    "\n",
    "Learning the parameters of a prediction function and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called overfitting.   \n",
    "To avoid it, it is common practice when performing a (supervised) machine learning experiment to hold out part of the available data as a test set.\n",
    "\n",
    "There is still a risk of overfitting on the test set because the parameters can be tweaked until the estimator performs optimally. This way, knowledge about the test set can “leak” into the model and evaluation metrics no longer report on generalization performance. To solve this problem, yet another part of the dataset can be held out as a so-called “validation set”: training proceeds on the training set, after which evaluation is done on the validation set, and when the experiment seems to be successful, final evaluation can be done on the test set.\n",
    "However, by partitioning the available data into three sets, we drastically reduce the number of samples which can be used for learning the model, and the results can depend on a particular random choice for the pair of (train, validation) sets.\n",
    "\n",
    "A solution to this problem is a procedure called <b>cross-validation (CV for short)</b>.\n",
    "A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV. In the basic approach, called k-fold CV, the training set is split into k smaller sets (other approaches are described below, but generally follow the same principles). The following procedure is followed for each of the k “folds”:\n",
    "\n",
    "A model is trained using k-1 of the folds as training data;\n",
    "the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).\n",
    "The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop. This approach can be computationally expensive, but does not waste too much data (as it is the case when fixing an arbitrary test set), which is a major advantage in problem such as inverse inference where the number of samples is very small.\n",
    "<br>\n",
    "\n",
    "Below, we have incorporated cross validation technique on training data for all the algorithms and found the accuracy range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Reading training and heldout data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import csv\n",
    "\n",
    "reader=csv.reader(open(\"Data/EssentialsofML/trainingFilteredWithNewFeatures.csv\",\"rb\"),delimiter=',')\n",
    "result=numpy.matrix(list(reader))[1:]\n",
    "\n",
    "X = result[:,5:].astype('int')\n",
    "y = numpy.squeeze(numpy.asarray(result[:,4]))\n",
    "\n",
    "readerHeldout=csv.reader(open(\"Data/EssentialsofML/heldoutFilteredWithNewFeatures.csv\",\"rb\"),delimiter=',')\n",
    "resultHeldout=numpy.matrix(list(readerHeldout))[1:]\n",
    "\n",
    "heldoutX = resultHeldout[:,5:].astype('int')\n",
    "heldouty = numpy.squeeze(numpy.asarray(resultHeldout[:,4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Support vector machines (SVMs) </h3>\n",
    "\n",
    "SVMs are a set of supervised learning methods used for classification, regression and outliers detection.\n",
    "\n",
    "The advantages of support vector machines are:<pre>\n",
    "1.Effective in high dimensional spaces.\n",
    "2.Still effective in cases where number of dimensions is greater than the number of samples.\n",
    "3.Uses a subset of training points in the decision function (called support vectors), so it is also memory     efficient.\n",
    "4.Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.</pre>\n",
    "\n",
    "The disadvantages of support vector machines include:<pre>\n",
    "1.If the number of features is much greater than the number of samples, the method is likely to give poor performances.\n",
    "2.SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation.</pre>\n",
    "\n",
    "<h5>Class required to implement support vector machines </h5><br>\n",
    "class sklearn.svm.SVC(C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape=None, random_state=None)\n",
    "\n",
    "To read more, follow : http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cross validation for SVM</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for SVM: 0.58 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#create model\n",
    "clf = svm.SVC()\n",
    "\n",
    "#Evaluate a score by cross-validation\n",
    "scores = cross_val_score(clf, X, y, cv=2)\n",
    "\n",
    "#report accuracy\n",
    "print(\"Accuracy for SVM: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>SVM on heldout data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#create model\n",
    "clf = svm.SVC()\n",
    "\n",
    "#fit the model according to the training data.\n",
    "clf.fit(X, y)\n",
    "\n",
    "#predict labels for heldout data\n",
    "predictedy = clf.predict(heldoutX)\n",
    "\n",
    "#print precision recall table\n",
    "print(classification_report(heldouty, predictedy))\n",
    "\n",
    "#report accuracy on heldout data\n",
    "print \"Accuracy= \",clf.score(heldoutX, heldouty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.Random forest classifier.</h3>\n",
    "\n",
    "A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and use averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is always the same as the original input sample size but the samples are drawn with replacement if bootstrap=True (default).\n",
    "\n",
    "<h5>Class required to implement random forest classifier</h5><br>\n",
    "class sklearn.ensemble.RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_split=1e-07, bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0, warm_start=False, class_weight=None)\n",
    "\n",
    "To read more, follow : http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cross validation for Random Forest Classifier</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest Classifier: 0.75 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#create model\n",
    "clf3 = RandomForestClassifier(n_estimators=50)\n",
    "\n",
    "#Evaluate a score by cross-validation\n",
    "scores3 = cross_val_score(clf3, X, y, cv=10)\n",
    "\n",
    "#report accuracy\n",
    "print(\"Accuracy for Random Forest Classifier: %0.2f (+/- %0.2f)\" % (scores3.mean(), scores3.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Random forest classifier on heldout data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.89      0.44      0.59        54\n",
      "          B       0.78      0.79      0.79       860\n",
      "          D       0.89      0.45      0.59       228\n",
      "          T       0.71      0.81      0.76       853\n",
      "\n",
      "avg / total       0.77      0.75      0.75      1995\n",
      "\n",
      "Accuracy=  0.752882205514\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#create model\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#fit the model according to the training data.\n",
    "clf.fit(X, y)\n",
    "\n",
    "#predict labels for heldout data\n",
    "predictedy = clf.predict(heldoutX)\n",
    "\n",
    "#print precision recall table\n",
    "print(classification_report(heldouty, predictedy))\n",
    "\n",
    "#report accuracy on heldout data\n",
    "print \"Accuracy= \",clf.score(heldoutX, heldouty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Logistic Regression (aka logit, MaxEnt) classifier</h3>\n",
    "\n",
    "In the multiclass case, the training algorithm uses the one-vs-rest (OvR) scheme if the ‘multi_class’ option is set to ‘ovr’, and uses the cross- entropy loss if the ‘multi_class’ option is set to ‘multinomial’. (Currently the ‘multinomial’ option is supported only by the ‘lbfgs’, ‘sag’ and ‘newton-cg’ solvers.)\n",
    "\n",
    "This class implements regularized logistic regression using the ‘liblinear’ library, ‘newton-cg’, ‘sag’ and ‘lbfgs’ solvers. It can handle both dense and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit floats for optimal performance; any other input format will be converted (and copied).\n",
    "\n",
    "The ‘newton-cg’, ‘sag’, and ‘lbfgs’ solvers support only L2 regularization with primal formulation. The ‘liblinear’ solver supports both L1 and L2 regularization, with a dual formulation only for the L2 penalty.\n",
    "\n",
    "<h5>Class required to implement Logistic Regression (aka logit, MaxEnt) classifier</h5><br>\n",
    "class sklearn.linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='liblinear', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "\n",
    "To read more, follow : http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cross validation for Logistic Regression</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#create model\n",
    "clf2 = LogisticRegressionCV()\n",
    "\n",
    "#Evaluate a score by cross-validation\n",
    "scores2 = cross_val_score(clf2, X, y, cv=3)\n",
    "\n",
    "#report accuracy\n",
    "print(\"Accuracy for Logistic Regression: %0.2f (+/- %0.2f)\" % (scores2.mean(), scores2.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Logistic Regression Classifier on heldout data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#create model\n",
    "clf =  LogisticRegressionCV()\n",
    "\n",
    "#fit the model according to the training data.\n",
    "clf.fit(X, y)\n",
    "\n",
    "#predict labels for heldout data\n",
    "predictedy = clf.predict(heldoutX)\n",
    "\n",
    "#print precision recall table\n",
    "print(classification_report(heldouty, predictedy))\n",
    "\n",
    "#report accuracy on heldout data\n",
    "print \"Accuracy= \",clf.score(heldoutX, heldouty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4. Decision trees </h3>\n",
    "\n",
    "Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.\n",
    "\n",
    "<h5>Class required to implement Decision trees </h5><br>\n",
    "class sklearn.tree.DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_split=1e-07, class_weight=None, presort=False)\n",
    "\n",
    "To read more, follow : http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cross validation for Decision Tree Classifier</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Decision Tree Classifier: 0.65 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#create model\n",
    "clf1 = tree.DecisionTreeClassifier()\n",
    "\n",
    "#Evaluate a score by cross-validation\n",
    "scores1 = cross_val_score(clf1, X, y, cv=10)\n",
    "\n",
    "#report accuracy\n",
    "print(\"Accuracy for Decision Tree Classifier: %0.2f (+/- %0.2f)\" % (scores1.mean(), scores1.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Decision Tree Classifier on heldout data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.47      0.39      0.42        54\n",
      "          B       0.69      0.71      0.70       860\n",
      "          D       0.53      0.47      0.50       228\n",
      "          T       0.65      0.66      0.65       853\n",
      "\n",
      "avg / total       0.65      0.65      0.65      1995\n",
      "\n",
      "Accuracy=  0.651127819549\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#create model\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "#fit the model according to the training data.\n",
    "clf.fit(X, y)\n",
    "\n",
    "#predict labels for heldout data\n",
    "predictedy = clf.predict(heldoutX)\n",
    "\n",
    "#print precision recall table\n",
    "print(classification_report(heldouty, predictedy))\n",
    "\n",
    "#report accuracy on heldout data\n",
    "print \"Accuracy= \",clf.score(heldoutX, heldouty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Comparison between the above implemented algorithms</h3><br>\n",
    "<table>\n",
    "<tr>\n",
    "<td><b>Classification Algorithm</b></td>\n",
    "<td><b>Accuracy</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>SVM</td>\n",
    "<td>0.597493734336</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Random Forest</td>\n",
    "<td>0.726817042607</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Logistic Regression</td>\n",
    "<td>0.7609022556397</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Decision Tree</td>\n",
    "<td>0.65313283208</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>References</h2>\n",
    "<br>\n",
    "Scikit Learn : http://scikit-learn.org\n",
    "<br>\n",
    "Numpy : http://www.numpy.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Developers</h2>\n",
    "<ul>\n",
    "<li>Bhargavkumar Patel <a href=\"mailto:bhargav079@gmail.com\">bhargav079@gmail.com</a><br></li>\n",
    "<li>Minesh Gandhi <a href=\"mailto:mineshmini33@gmail.com\">mineshmini33@gmail.com</a><br></li>\n",
    "<li>Prachi Agarwal <a href=\"mailto:24prachiagarwal@gmail.com\">24prachiagarwal@gmail.com</a></li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
