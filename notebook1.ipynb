{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "70894730-f4d6-4a45-8e3d-1dc5c282bca3"
    }
   },
   "source": [
    "<h1 align=\"center\">Parsing with Context Free Grammars(CFG) and PCFG (Probabilistic CFG)</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "0c213053-41a5-475b-8311-ac785dca697f"
    }
   },
   "source": [
    "<h3>1. Context Free Grammars</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f15f2986-d737-40ba-ad12-dd255069807c"
    }
   },
   "source": [
    "- Let's consider a simple grammar. By convention, the left-hand-side of the first production is the start-symbol of the grammar, typically S, and all well-formed trees must have this symbol as their root label.\n",
    "-  In NLTK, context-free grammars are defined in the nltk.grammar module.\n",
    "- Steps\n",
    "    - Import ntk\n",
    "    - Create grammar\n",
    "    - Parse the string\n",
    "    - Print the parse tree\n",
    "- Following is an example taken from NLTK-book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "1b38753f-f5a8-427d-a3da-d613c19576fc"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Parse trees : \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEMCAMAAAAf2ZYHAAAJJGlDQ1BpY2MAAHjalZVnUJNZF8fv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\nLTMuMAqbcLvjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#code snippet taken from http://www.nltk.org/book/\n",
    "\n",
    "import nltk\n",
    "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "VP -> V NP | V NP PP\n",
    "PP -> P NP\n",
    "V -> \"saw\" | \"ate\" | \"walked\"\n",
    "NP -> \"John\" | \"Mary\" | \"Bob\" | Det N | Det N PP\n",
    "Det -> \"a\" | \"an\" | \"the\" | \"my\"\n",
    "N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\"\n",
    "P -> \"in\" | \"on\" | \"by\" | \"with\"\n",
    "\"\"\")\n",
    "sent = \"Mary saw Bob\".split()\n",
    "parser = nltk.ChartParser(grammar1)\n",
    "\n",
    "#showing parsed trees\n",
    "\n",
    "num_of_parse = len(list(parser.parse(sent)))\n",
    "\n",
    "print(num_of_parse,\"Parse trees : \")\n",
    "\n",
    "from nltk import Tree\n",
    "from nltk.draw.util import CanvasFrame\n",
    "from nltk.draw import TreeWidget\n",
    "\n",
    "import os\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "c =0\n",
    "for tree in parser.parse(sent):\n",
    "    cf = CanvasFrame()\n",
    "    t = Tree.fromstring(str(tree))\n",
    "    tc = TreeWidget(cf.canvas(),t)\n",
    "    cf.add_widget(tc,10,10) # (10,10) offsets\n",
    "    cf.print_to_file('tree'+str(c)+'.ps')\n",
    "    cf.destroy()\n",
    "    \n",
    "    os.system('convert tree'+str(c)+'.ps tree'+str(c)+'.png')\n",
    "    \n",
    "    display(Image(filename='./tree'+str(c)+'.png'))\n",
    "    \n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "85e969e1-b3ef-4de3-977e-d9afc42b7011"
    }
   },
   "source": [
    "<h3>Another example with address parsing</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1dad07fe-8456-4bc0-bc11-a6efad0b7b91"
    }
   },
   "source": [
    "- We want to parse home addresses using CFG. Address consists of 2 lines of addresses containing house number, street/road/avenue,floor number, region (north,east,south,west), and other details.\n",
    "- Here we have used a regular expression-tagger to tag the sequence of words in the address lines with tags such as 'NUM', 'STREET', etc.\n",
    "- For example,\n",
    "                'suite' and 'Suite' are tagged to 'SUITE'\n",
    "                'floor' and 'Floor' are tagged to 'FLOOR'\n",
    "                 sequence of number is tagged as 'NUM'\n",
    "- A CFG can be formed as follows, for the address \"525 N. Main Street , Suite 28\" as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "ea15ad0a-1cc4-49e3-bd79-5a8e29b9a8f4"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Parse trees : \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEMCAMAAAAf2ZYHAAAJJGlDQ1BpY2MAAHjalZVnUJNZF8fv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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nltk\n",
    "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
    "S -> ADD1 ADD2 | ADD1\n",
    "ADD1 -> N DIR ST | ST | N DIR\n",
    "ADD2 -> FL ST | FL | SUI | SUI FL | SUI FL ST | FL SUI \n",
    "N -> 'NUM'\n",
    "DIR -> 'N.' | 'S.' | 'W.'|'E.'|'North'|'South'|'West'|'East'|'N'|'S'|'E'|'W'\n",
    "ST -> 'STREET' ST | 'STREET'\n",
    "SUI -> SU N\n",
    "FL -> N SS F | N F\n",
    "F -> 'FLOOR'\n",
    "SU -> 'SUITE' | 'Suite'\n",
    "SS -> 'SUP'\n",
    "\"\"\")\n",
    "pattern = [(r'[0-9]+','NUM'),(r'^(?!(N|W|E|S|N.|S.|W.|E.|West|North|East|,|South|Suite|Floor|floor|nd|st|th)$).*','STREET'),(r'(Suite,suite)+','SUITE'),(r'(nd|st|th)','SUP'),(r'(floor|Floor)','FLOOR'),(r',','COM')]\n",
    "tagger = nltk.RegexpTagger(pattern)\n",
    "\n",
    "t=[]\n",
    "#print(tagger.tag(nltk.word_tokenize('525 N. Main Street , Suite 28')))\n",
    "for (y,x) in (tagger.tag(nltk.word_tokenize('525 N. Main Street , Suite 28'))):\n",
    "\tif x is not None and x != 'COM':\n",
    "\t\tt.append(x)\n",
    "\telif x is None :\n",
    "\t\tt.append(y)\n",
    "#print (t)\n",
    "parser = nltk.ChartParser(grammar1)\n",
    "\n",
    "#showing parsed trees\n",
    "\n",
    "num_of_parse = len(list(parser.parse(t)))\n",
    "\n",
    "print(num_of_parse,\"Parse trees : \")\n",
    "\n",
    "from nltk import Tree\n",
    "from nltk.draw.util import CanvasFrame\n",
    "from nltk.draw import TreeWidget\n",
    "\n",
    "import os\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "c =0\n",
    "for tree in parser.parse(t):\n",
    "    cf = CanvasFrame()\n",
    "    t = Tree.fromstring(str(tree))\n",
    "    tc = TreeWidget(cf.canvas(),t)\n",
    "    cf.add_widget(tc,10,10) # (10,10) offsets\n",
    "    #Saving output in form of .ps file\n",
    "    cf.print_to_file('tree'+str(c)+'.ps')\n",
    "    cf.destroy()\n",
    "    #Saving output of tree as .png file and loading it in next step\n",
    "    os.system('convert tree'+str(c)+'.ps tree'+str(c)+'.png')\n",
    "    \n",
    "    display(Image(filename='./tree'+str(c)+'.png'))\n",
    "    \n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "556fa1de-6b47-45b2-aba2-4e5ef374e054"
    }
   },
   "source": [
    "- Parsing is performed using this tagged sequence only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ea9422e8-9a34-4071-a25f-fc41f9f5b4fa"
    }
   },
   "source": [
    "<h3>2.1 A modified cfg</h3>\n",
    "<pre>\n",
    "Following grammar is the extension of the above grammer having fields: name, address_line_1, address_line_2,  city, state, country and zip.\n",
    "Regex Tagger is also updated accordingly.\n",
    "Out of 13078 addresses, 7541 are being parsed properly.\n",
    "Strings like \"<b>773-702-7034 Carl Sandburg Middle School , 855 W. Hawley Street , LOCATED IN THE GYM ,Mundelein, IL , us , 60060</b>\" is not parsed by the following grammar because \"<b>773-702-7034</b>\" format is not taken in number tag.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "dfc7ba72-9ff5-462b-bde6-d6572e38cf75"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed :  7541 / 13078\n",
      "Accuracy :  57.66172197583729\n",
      "CPU times: user 1min 40s, sys: 4 ms, total: 1min 40s\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import nltk\n",
    "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
    "S ->  N NM ADD1 ADD2 CT STATE COUNTRY Z |NM ADD1 ADD2 CT STATE COUNTRY Z| NM ADD1 CT STATE COUNTRY Z\n",
    "NM -> 'NAME' NM | 'NAME' 'NUM' NM | 'NAME' 'NUM' | 'NAME'\n",
    "ADD1 -> N DIR ST | ST | N DIR | N DIR AVE | AVE | N AVE | N ST |AVE N| ST N | AVE DIR |ST DIR | AVE DIR AVE| AVE DIR AVE |ST DIR ST |AVE N AVE | ST N ST | N DIR N SS AVE |N DIR N SS ST | N DIR N SS AVE |N DIR N SS ST |  DIR AVE |DIR ST\n",
    "ADD2 -> FL ST1 | FL | SUI | SUI FL | SUI FL ST1 | FL SUI | DIR ST1 |N DIR ST1 | ST1 | N DIR | N ST1 | N SS ST1 | ST1 N |ST1 DIR ST1 | 'NUM'\n",
    "N -> 'NUM' \n",
    "CT -> 'CITY' | 'CITY' 'CITY' | 'CITY' 'CITY' 'CITY'\n",
    "STATE -> 'STATE' | STATE 'STATE'\n",
    "Z -> 'ZIP'\n",
    "COUNTRY -> 'COUNTRY'| COUNTRY 'COUNTRY'|'us'|'US'\n",
    "DIR -> 'N.' | 'S.' | 'W.'|'E.'|'North'|'South'|'West'|'East'|'N'|'S'|'E'|'W'|'w.'|'s.'|'n.'|'e.'\n",
    "ST -> 'STREET1' ST | 'STREET1' 'NUM' | 'STREET1' 'NUM' ST| 'STREET1'\n",
    "AVE -> 'AVENUE' AVE | 'AVENUE'\n",
    "ST1 -> 'STREET2' ST1 | 'STREET2'\n",
    "SUI -> SU N\n",
    "FL -> N SS F | N F | OTH F | F N SS\n",
    "OTH -> 'Top' | 'Main'\n",
    "F -> 'FLOOR'\n",
    "SU -> 'SUITE'\n",
    "SS -> 'SUP'\n",
    "\"\"\")\n",
    "\t\n",
    "pattern = [(r'^(?!(?:^[0-9][0-9][0-9][0-9][0-9]+$)$)\\d+','NUM'),(r'^(?!(?:^[0-9][0-9][0-9][0-9][0-9]+$)|(\\(|\\)|us|US|N\\.|W\\.|E\\.|S\\.|N|W|E|S|n\\.|w\\.|e\\.|s\\.|Ave|Ave\\.|ave|avenue|Avenue|AVENUE|ave\\.|,|Suite|suite|SUITE|Floor|Fl.|Fl|floor|nd|th)$).*','STREET1'),(r'(Suite|suite|SUITE)','SUITE'),(r'(nd|th)','SUP'),(r'(floor|Fl.|Fl|Floor)','FLOOR'),(r',','COM'),(r'\\(|\\)','BRAC'),(r'Ave|Ave.|ave|avenue|Avenue|AVENUE|ave.','AVENUE'),(r'^[0-9][0-9][0-9][0-9][0-9]+$','ZIP')]\n",
    "\n",
    "f = open(\"data/all_addr.csv\",encoding=\"utf-8\")\n",
    "\n",
    "count = 0\n",
    "total_count = 0\n",
    "for line in f:\n",
    "    adr1 = line\n",
    "    #print(adr1)\n",
    "    tagger = nltk.RegexpTagger(pattern)\n",
    "    #adr1 = 'Miguel , private location , details to be emailed to those attending , Evanston , IL , us , 60202'\n",
    "    t=[]\n",
    "    f=0\n",
    "    p=0\n",
    "    start=0\n",
    "    end=0\n",
    "    for (y,x) in (tagger.tag(nltk.word_tokenize(adr1))):\n",
    "        if x is not None and x != 'COM' and x != 'BRAC' and f==0:\t\n",
    "            if x is 'STREET1' :\n",
    "                x='NAME'\n",
    "            t.append(x)\n",
    "        elif x is not None and x != 'COM' and x != 'BRAC' and f==1:\n",
    "            t.append(x)\n",
    "        elif x is not None and x != 'COM' and x != 'BRAC' and f==2:\t\n",
    "            if x is 'STREET1' :\n",
    "                x='STREET2'\n",
    "            t.append(x)\n",
    "        elif x is not None and x != 'COM' and x != 'BRAC' and f==3:\t\n",
    "            if x is 'STREET1' :\n",
    "                x='CITY'\n",
    "            t.append(x)\n",
    "        elif x is not None and x != 'COM' and x != 'BRAC' and f==4:\t\n",
    "            if x is 'STREET1' :\n",
    "                x='STATE'\n",
    "            t.append(x)\n",
    "        elif x is not None and x != 'COM' and x != 'BRAC' and f==5:\t\n",
    "            if x is 'STREET1' :\n",
    "                x='COUNTRY'\n",
    "            t.append(x)     \n",
    "        elif x is not None and x != 'COM' and x != 'BRAC' and f==6:\t\n",
    "            t.append(x)\t\t\n",
    "        elif x == 'COM' :\n",
    "            f+=1\n",
    "        elif x is None  :\n",
    "            t.append(y)\n",
    "    if 'AVENUE' in t :\n",
    "        p=1\n",
    "    if p==1:\n",
    "        for index, item in enumerate(t):\n",
    "            if 'STREET1' in item :\n",
    "                start=index\n",
    "                break\n",
    "        for index, item in enumerate(t):\n",
    "            if 'AVENUE' in item :\n",
    "                end=index\n",
    "                break\n",
    "        for i in range(start,end) :\n",
    "            t[i]='AVENUE'\n",
    "\n",
    "\n",
    "\n",
    "    #print(t)\n",
    "\n",
    "    parser = nltk.ChartParser(grammar1)\n",
    "    num_of_parse = len(list(parser.parse(t)))\n",
    "\n",
    "    #print(num_of_parse)\n",
    "\n",
    "    if num_of_parse>0:\n",
    "        count += 1\n",
    "    total_count += 1\n",
    "\n",
    "    #for tree in parser.parse(t):\n",
    "        #tree.draw()\n",
    "\n",
    "print(\"Parsed : \",count,\"/\",total_count)\n",
    "print(\"Accuracy : \",(count/total_count)*100.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Ambiguity in Grammar</h3>\n",
    "<pre>\n",
    "There are several addresses which lead to more than one parse tree, after being parsed by the above grammar.\n",
    "Here is an example of an ambiguity taking \"<b>Harold Washington Library Center , 400 S. State Street , Cindy Pritzker Auditorium , Chicago , IL , us , 60605</b>\" as input.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Parse trees : \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "adr1 = 'Harold Washington Library Center , 400 S. State Street , Cindy Pritzker Auditorium , Chicago , IL , us , 60605'\n",
    "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
    "S ->  N NM ADD1 ADD2 CT STATE COUNTRY Z |NM ADD1 ADD2 CT STATE COUNTRY Z| NM ADD1 CT STATE COUNTRY Z\n",
    "NM -> 'NAME' NM | 'NAME' 'NUM' NM | 'NAME' 'NUM' | 'NAME'\n",
    "ADD1 -> N DIR ST | ST | N DIR | N DIR AVE | AVE | N AVE | N ST |AVE N| ST N | AVE DIR |ST DIR | AVE DIR AVE| AVE DIR AVE |ST DIR ST |AVE N AVE | ST N ST | N DIR N SS AVE |N DIR N SS ST | N DIR N SS AVE |N DIR N SS ST |  DIR AVE |DIR ST\n",
    "ADD2 -> FL ST1 | FL | SUI | SUI FL | SUI FL ST1 | FL SUI | DIR ST1 |N DIR ST1 | ST1 | N DIR | N ST1 | N SS ST1 | ST1 N |ST1 DIR ST1 | 'NUM'\n",
    "N -> 'NUM' \n",
    "CT -> 'CITY' | 'CITY' 'CITY' | 'CITY' 'CITY' 'CITY'\n",
    "STATE -> 'STATE' | STATE 'STATE'\n",
    "Z -> 'ZIP'\n",
    "COUNTRY -> 'COUNTRY'| COUNTRY 'COUNTRY'|'us'|'US'\n",
    "DIR -> 'N.' | 'S.' | 'W.'|'E.'|'North'|'South'|'West'|'East'|'N'|'S'|'E'|'W'|'w.'|'s.'|'n.'|'e.'\n",
    "ST -> 'STREET1' ST | 'STREET1' 'NUM' | 'STREET1' 'NUM' ST| 'STREET1'\n",
    "AVE -> 'AVENUE' AVE | 'AVENUE'\n",
    "ST1 -> 'STREET2' ST1 | 'STREET2'\n",
    "SUI -> SU N\n",
    "FL -> N SS F | N F | OTH F | F N SS\n",
    "OTH -> 'Top' | 'Main'\n",
    "F -> 'FLOOR'\n",
    "SU -> 'SUITE'\n",
    "SS -> 'SUP'\n",
    "\"\"\")\n",
    "\t\n",
    "pattern = [(r'^(?!(?:^[0-9][0-9][0-9][0-9][0-9]+$)$)\\d+','NUM'),(r'^(?!(?:^[0-9][0-9][0-9][0-9][0-9]+$)|(\\(|\\)|us|US|N\\.|W\\.|E\\.|S\\.|N|W|E|S|n\\.|w\\.|e\\.|s\\.|Ave|Ave\\.|ave|avenue|Avenue|AVENUE|ave\\.|,|Suite|suite|SUITE|Floor|Fl.|Fl|floor|nd|th)$).*','STREET1'),(r'(Suite|suite|SUITE)','SUITE'),(r'(nd|th)','SUP'),(r'(floor|Fl.|Fl|Floor)','FLOOR'),(r',','COM'),(r'\\(|\\)','BRAC'),(r'Ave|Ave.|ave|avenue|Avenue|AVENUE|ave.','AVENUE'),(r'^[0-9][0-9][0-9][0-9][0-9]+$','ZIP')]\n",
    "tagger = nltk.RegexpTagger(pattern)\n",
    "\n",
    "t=[]\n",
    "f=0\n",
    "p=0\n",
    "start=0\n",
    "end=0\n",
    "for (y,x) in (tagger.tag(nltk.word_tokenize(adr1))):\n",
    "    if x is not None and x != 'COM' and x != 'BRAC' and f==0:\t\n",
    "        if x is 'STREET1' :\n",
    "            x='NAME'\n",
    "        t.append(x)\n",
    "    elif x is not None and x != 'COM' and x != 'BRAC' and f==1:\n",
    "        t.append(x)\n",
    "    elif x is not None and x != 'COM' and x != 'BRAC' and f==2:\t\n",
    "        if x is 'STREET1' :\n",
    "            x='STREET2'\n",
    "        t.append(x)\n",
    "    elif x is not None and x != 'COM' and x != 'BRAC' and f==3:\t\n",
    "        if x is 'STREET1' :\n",
    "            x='CITY'\n",
    "        t.append(x)\n",
    "    elif x is not None and x != 'COM' and x != 'BRAC' and f==4:\t\n",
    "        if x is 'STREET1' :\n",
    "            x='STATE'\n",
    "        t.append(x)\n",
    "    elif x is not None and x != 'COM' and x != 'BRAC' and f==5:\t\n",
    "        if x is 'STREET1' :\n",
    "            x='COUNTRY'\n",
    "        t.append(x)     \n",
    "    elif x is not None and x != 'COM' and x != 'BRAC' and f==6:\t\n",
    "        t.append(x)\t\t\n",
    "    elif x == 'COM' :\n",
    "        f+=1\n",
    "    elif x is None  :\n",
    "        t.append(y)\n",
    "if 'AVENUE' in t :\n",
    "    p=1\n",
    "if p==1:\n",
    "    for index, item in enumerate(t):\n",
    "        if 'STREET1' in item :\n",
    "            start=index\n",
    "            break\n",
    "    for index, item in enumerate(t):\n",
    "        if 'AVENUE' in item :\n",
    "            end=index\n",
    "            break\n",
    "    for i in range(start,end) :\n",
    "        t[i]='AVENUE'\n",
    "\n",
    "parser = nltk.ChartParser(grammar1)\n",
    "\n",
    "\n",
    "num_of_parse = len(list(parser.parse(t)))\n",
    "\n",
    "print(num_of_parse,\"Parse trees : \")\n",
    "\n",
    "from nltk import Tree\n",
    "from nltk.draw.util import CanvasFrame\n",
    "from nltk.draw import TreeWidget\n",
    "\n",
    "import os\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "c =0\n",
    "for tree in parser.parse(t):\n",
    "    cf = CanvasFrame()\n",
    "    t = Tree.fromstring(str(tree))\n",
    "    tc = TreeWidget(cf.canvas(),t)\n",
    "    cf.add_widget(tc,10,10) # (10,10) offsets\n",
    "    cf.print_to_file('tree'+str(c)+'.ps')\n",
    "    cf.destroy()\n",
    "    \n",
    "    os.system('convert tree'+str(c)+'.ps tree'+str(c)+'.png')\n",
    "    \n",
    "    display(Image(filename='./tree'+str(c)+'.png'))\n",
    "    \n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "15d55141-ecc5-493d-82c1-7d6381d45518"
    }
   },
   "source": [
    "<h3>3. CYK algorithm</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "0807e5aa-1601-4cb1-8831-fc8e3bf4d156"
    }
   },
   "source": [
    "- CYK is a parsing algorithm for context-free grammars which employs bottom-up parsing and dynamic programming.\n",
    "- The standard version of CYK operates only on context-free grammars given in Chomsky normal form (CNF). However any context-free grammar may be transformed to a CNF grammar expressing the same language.\n",
    "- In formal language theory, a grammar is said to be in Chomsky Norma Form(CNF) if all of its productions are of the form:\n",
    "    - A -> BC\n",
    "    - A -> a\n",
    "    - S -> null\n",
    "    where, where A, B, and C are nonterminal symbols, a is a terminal symbol (a symbol that represents a constant value), S is the start symbol, and Îµ denotes the empty string.\n",
    "- The importance of the CYK algorithm stems from its high efficiency in certain situations. The worst case running time of CYK is O((n^3)*|G|), where n is the length of the parsed string and |G| is the size of the CNF grammar G (Hopcroft & Ullman 1979, p. 140). This makes it one of the most efficient parsing algorithms in terms of worst-case asymptotic complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f407e8d7-d830-477d-9c43-2343db128138"
    }
   },
   "source": [
    "<a href=\"http://www.tutorialspoint.com/automata_theory/chomsky_normal_form.htm\">Useful resource on CNF conversion</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4c4270ad-cc10-4438-a67f-d5a5dd4032f3"
    }
   },
   "source": [
    "<h3>3.1 Example</h3>\n",
    "<p>The example shows implementation of a CYK algorithm.<br>\n",
    "Parsing is performed on simple string: \"the kids opened the box on the floor\".<br>\n",
    "Parsing is also peformed using Prbabilistic CFG in which each prouction is assigned a probability. So in case of unambiguous grammars in which more then one productions with same darivations are possible, probability is given to the highest production.</p>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "c67923a2-c477-4448-9b5b-3d105ddde603"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Det -> 'the' [1.0]]\n",
      "[N -> 'kids' [0.4], X -> 'kids' [1.0]]\n",
      "[V -> 'opened' [1.0]]\n",
      "[Det -> 'the' [1.0]]\n",
      "[N -> 'box' [0.3]]\n",
      "[P -> 'on' [1.0]]\n",
      "[Det -> 'the' [1.0]]\n",
      "[N -> 'floor' [0.3]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>TABLE</td><td>the[1]</td><td>kids[2]</td><td>opened[3]</td><td>the[4]</td><td>box[5]</td><td>on[6]</td><td>the[7]</td><td>floor[8]</td></tr><tr><td>0</td><td>Det [1.0 ]</br></td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td>1</td><td>-</td><td>N [0.4 ]</br>X [1.0 ]</br></td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td>2</td><td>-</td><td>-</td><td>V [1.0 ]</br></td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td>3</td><td>-</td><td>-</td><td>-</td><td>Det [1.0 ]</br></td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td>4</td><td>-</td><td>-</td><td>-</td><td>-</td><td>N [0.3 ]</br></td><td>-</td><td>-</td><td>-</td></tr><tr><td>5</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>P [1.0 ]</br></td><td>-</td><td>-</td></tr><tr><td>6</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>Det [1.0 ]</br></td><td>-</td></tr><tr><td>7</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>N [0.3 ]</br></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# code snippet taken from http://www.cs.pomona.edu/classes/cs181NLP/lectures/Lec11/Lec11.pdf\n",
    "import IPython\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "tokens = [\"the\", \"kids\", \"opened\", \"the\", \"box\", \"on\", \"the\", \"floor\"]\n",
    "# grammar is in CNF form for CYK algorithm\n",
    "grammar = nltk.PCFG.fromstring(\"\"\"\n",
    "S -> NP VP [1.0]\n",
    "PP -> P NP [1.0]\n",
    "NP -> Det N [0.4] | NP PP [0.6]\n",
    "VP -> V NP [0.5] | VP PP [0.5]\n",
    "Det -> 'the' [1.0]\n",
    "N -> 'kids' [0.4] | 'box' [0.3] | 'floor' [0.3]\n",
    "V -> 'opened' [1.0]\n",
    "P -> 'on' [1.0]\n",
    "X -> 'kids' [1.0]\n",
    "\"\"\")\n",
    "                               \n",
    "def init_wfst(tokens, grammar):\n",
    "    numtokens = len(tokens)    \n",
    "    \n",
    "    wfst = [[\"-\" for i in range(numtokens+1)] for j in range(numtokens+1)]\n",
    "    \n",
    "    # fill in diagonal\n",
    "    for i in range(numtokens):\n",
    "        productions = grammar.productions(rhs=tokens[i])\n",
    "        print(productions)\n",
    "        temp = \"\"\n",
    "        for prod in productions:\n",
    "            temp += str(prod.lhs()) + ' ['+ str(prod.prob()) +' ]</br>'\n",
    "        wfst[i][i+1] = temp\n",
    "    \n",
    "    return wfst\n",
    "\n",
    "def complete_wfst(wfst, tokens, trace=False):\n",
    "    index = {}\n",
    "    for prod in grammar.productions(): #make reverse lookup\n",
    "        index[prod.rhs()] = prod.lhs()\n",
    "    numtokens = len(tokens)\n",
    "    for span in range(2, numtokens+1):\n",
    "        for start in range(numtokens+1-span): #go down diagonal\n",
    "            end = start + span\n",
    "            for mid in range(start+1, end):\n",
    "                nt1, nt2 = wfst[start][mid], wfst[mid][end]\n",
    "                if (nt1,nt2) in index:\n",
    "                    if trace:\n",
    "                        '''\n",
    "                        format : \n",
    "                            [ i ] NT_RHS1 [ k ] NT_RHS2 [ j ] ==> [ PROD_NUM ] NT_LHS [ j ]\n",
    "                        \n",
    "                            It means\n",
    "                                NT_RHS1 can derive string (i,k]\n",
    "                                NT_RHS2 can derive string (k,j]\n",
    "                                \n",
    "                                Using NT_RHS1 and NT_RHS2 procuction number PROD_NUM can derive NT_LHS and string (i,j] which is of the form\n",
    "                                    NT_LHS -> NT_RHS1 NT_RHS2\n",
    "                            \n",
    "                        '''\n",
    "                        print( \"[%s] %3s [%s] %3s [%s] ==> [%s] %3s [%s]\" %(start, nt1, mid, nt2, end, start, index[(nt1,nt2)], end))\n",
    "                    wfst[start][end] = index[(nt1,nt2)]\n",
    "    return wfst \n",
    "\n",
    "def display(wfst, tokens):\n",
    "    print('\\nWFST\\t' + '\\t'.join([(\"%-4d\" % i) for i in range(1, len(wfst))]))\n",
    "    for i in range(len(wfst)-1):\n",
    "        print(\"%d\\t\" % i,end=\"\")\n",
    "        for j in range(1, len(wfst)):\n",
    "            print(\"%-4s\\t\" % wfst[i][j],end=\"\")\n",
    "        print()\n",
    "\n",
    "wfst = init_wfst(tokens, grammar)\n",
    "wfst = complete_wfst(wfst, tokens, trace=False)\n",
    "#display(wfst, tokens)\n",
    "\n",
    "wfst[0][0] = \"TABLE :P\"\n",
    "for x in range(0,len(wfst)):\n",
    "    wfst[x][0] = str(x)\n",
    "    \n",
    "wfst = wfst[:-1]\n",
    "temp = []\n",
    "for i in range(len(tokens)):\n",
    "    temp.append(tokens[i]+\"[%d]\"%(i+1))\n",
    "temp.insert(0,'TABLE')\n",
    "\n",
    "wfst.insert(0,temp)\n",
    "        \n",
    "\n",
    "IPython.display.display(HTML(\n",
    "    '<table><tr>{}</tr></table>'.format(\n",
    "        '</tr><tr>'.join(\n",
    "            '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) for row in wfst)\n",
    "        )\n",
    " ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "84d2d19b-abee-4913-97ff-d63f59307eb2"
    }
   },
   "source": [
    "<h3>3.2 Applying above CYK algorithm to parse address:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "2391da40-4267-48c7-a87c-7e392443f87f"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>[NM, X7]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[S]</td></tr><tr><td>[]</td><td>[ADD1, STREET1, ST]</td><td>[ST, ADD1]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[X1]</td></tr><tr><td>[]</td><td>[]</td><td>[ADD1, STREET1, ST]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[X1]</td></tr><tr><td>[]</td><td>[]</td><td>[]</td><td>[ADD2, STREET2, ST1]</td><td>[ADD2, ST1]</td><td>[ADD2, ST1]</td><td>[ADD2, ST1]</td><td>[ADD2, ST1]</td><td>[ADD2, ST1]</td><td>[ADD2, ST1]</td><td>[]</td><td>[]</td><td>[]</td><td>[X2]</td></tr><tr><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[ADD2, STREET2, ST1]</td><td>[ADD2, ST1]</td><td>[ADD2, ST1]</td><td>[ADD2, ST1]</td><td>[ADD2, ST1]</td><td>[ADD2, ST1]</td><td>[]</td><td>[]</td><td>[]</td><td>[X2]</td></tr><tr><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[ADD2, STREET2, ST1]</td><td>[ADD2, ST1]</td><td>[ADD2, ST1]</td><td>[ADD2, ST1]</td><td>[ADD2, ST1]</td><td>[]</td><td>[]</td><td>[]</td><td>[X2]</td></tr><tr><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[ADD2, STREET2, ST1]</td><td>[ADD2, ST1]</td><td>[ADD2, ST1]</td><td>[ADD2, ST1]</td><td>[]</td><td>[]</td><td>[]</td><td>[X2]</td></tr><tr><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[ADD2, STREET2, ST1]</td><td>[ADD2, ST1]</td><td>[ADD2, ST1]</td><td>[]</td><td>[]</td><td>[]</td><td>[X2]</td></tr><tr><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[ADD2, STREET2, ST1]</td><td>[ADD2, ST1]</td><td>[]</td><td>[]</td><td>[]</td><td>[X2]</td></tr><tr><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[ADD2, STREET2, ST1]</td><td>[]</td><td>[]</td><td>[]</td><td>[X2]</td></tr><tr><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[CITY, CT]</td><td>[]</td><td>[]</td><td>[X3]</td></tr><tr><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[STATE]</td><td>[]</td><td>[X4]</td></tr><tr><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[COUNTRY]</td><td>[X5]</td></tr><tr><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[Z]</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "adr1 = \"Miguel , private location , details to be emailed to those attending , Evanston , IL , us , 60202\"\n",
    "\n",
    "grammar1 = \\\n",
    "    nltk.CFG.fromstring(\"\"\"\n",
    "S -> NM X1 | NM X6\n",
    "X6 -> ADD1 X3\n",
    "X1 -> ADD1 X2\n",
    "X2 -> ADD2 X3\n",
    "X3 -> CT X4\n",
    "X4 -> STATE X5\n",
    "X5 -> COUNTRY Z\n",
    "NM -> X7 NM | X7 X8 | X7 N | 'NAME'\n",
    "X7 -> 'NAME'\n",
    "X8 -> N NM \n",
    "ADD1 -> X9 ST | ST STREET1 | 'STREET1' | N DIR | X9 AVE | AVENUE AVE | 'AVENUE' | N ST\n",
    "X9 -> N DIR\n",
    "ADD2 -> FL ST1 | X11 F | N F | OTH F | F X11 | SU N | SUI FL | SUI X13 | FL SUI | DIR ST1 | N X14 | STREET2 ST1 | 'STREET2' | N DIR | N ST1 | N X15 | ST1 N |ST1 X16 | 'NUM'\n",
    "X16 -> DIR ST1\n",
    "X15 -> SS ST1\n",
    "X14 -> DIR ST1\n",
    "X13 -> FL ST1\n",
    "N -> 'NUM' \n",
    "CITY -> 'CITY'\n",
    "CT -> 'CITY' | CITY CITY\n",
    "STATE -> 'IL'\n",
    "Z -> 'ZIP'\n",
    "COUNTRY -> 'us' | 'US'\n",
    "DIR -> 'N.' | 'S.' | 'W.'|'E.'|'North'|'South'|'West'|'East'|'N'|'S'|'E'|'W'|'w.'|'s.'|'n.'|'e.'\n",
    "STREET1 -> 'STREET1'\n",
    "ST -> STREET1 ST | STREET1 N | STREET1 X10 | 'STREET1'\n",
    "X10 -> N ST\n",
    "AVE -> AVENUE AVE | 'AVENUE'\n",
    "AVENUE -> 'AVENUE'\n",
    "STREET2 ->\t'STREET2'\n",
    "ST1 -> STREET2 ST1 | 'STREET2'\n",
    "SUI -> SU N\n",
    "FL -> X11 F | N F | OTH F | F X11\n",
    "X11 -> N SS\n",
    "OTH -> 'Top' | 'Main'\n",
    "F -> 'FLOOR'\n",
    "SU -> 'SUITE'\n",
    "SS -> 'SUP'\n",
    "\"\"\")\n",
    "\n",
    "pattern = [(r'^(?!(?:^6[0-9]{4,4}$)$)\\d+','NUM'),(r'^(?!(?:^6[0-9]{4,4}$)|(\\(|\\)|IL|us|US|N\\.|W\\.|E\\.|S\\.|N|W|E|S|n\\.|w\\.|e\\.|s\\.|Ave|Ave\\.|ave|avenue|Avenue|AVENUE|ave\\.|West|North|East|,|South|Suite|suite|SUITE|Floor|Fl.|Fl|floor|nd|th)$).*','STREET1'),(r'(Suite|suite|SUITE)','SUITE'),(r'(nd|th)','SUP'),(r'(floor|Fl.|Fl|Floor)','FLOOR'),(r',','COM'),(r'\\(|\\)','BRAC'),(r'Ave|Ave.|ave|avenue|Avenue|AVENUE|ave.','AVENUE'),(r'^6[0-9]{4,4}$','ZIP')]\n",
    "tagger = nltk.RegexpTagger(pattern)\n",
    "    \n",
    "t = []\n",
    "f = 0\n",
    "p = 0\n",
    "start = 0\n",
    "end = 0\n",
    "for (y, x) in tagger.tag(nltk.word_tokenize(adr1)):\n",
    "    if x is not None and x != 'COM' and x != 'BRAC' and f == 0:\n",
    "        if x == 'STREET1':\n",
    "            x = 'NAME'\n",
    "        t.append(x)\n",
    "    elif x != None and x != 'COM' and x != 'BRAC' and f == 1:\n",
    "        t.append(x)\n",
    "    elif x != None and x != 'COM' and x != 'BRAC' and f == 2:\n",
    "        if x == 'STREET1':\n",
    "            x = 'STREET2'\n",
    "        t.append(x)\n",
    "    elif x != None and x != 'COM' and x != 'BRAC' and f == 3:\n",
    "        if x == 'STREET1':\n",
    "            x = 'CITY'\n",
    "        t.append(x)\n",
    "    elif x != None and x != 'COM' and x != 'BRAC' and f == 6:\n",
    "        t.append(x)\n",
    "    elif x == 'COM':\n",
    "        f += 1\n",
    "    elif x == None:\n",
    "        t.append(y)\n",
    "\n",
    "if 'AVENUE' in t:\n",
    "    p = 1\n",
    "\n",
    "if p == 1:\n",
    "    for (index, item) in enumerate(t):\n",
    "        if 'STREET1' in item:\n",
    "            start = index\n",
    "            break\n",
    "    for (index, item) in enumerate(t):\n",
    "        if 'AVENUE' in item:\n",
    "            end = index\n",
    "            break\n",
    "    for i in range(start, end):\n",
    "        t[i] = 'AVENUE'\n",
    "\n",
    "tokens = t\n",
    "grammar = grammar1\n",
    "    \n",
    "size = len(tokens)\n",
    "\n",
    "#creating table\n",
    "table = [ [[] for i in range(size)] for i in range(size) ]\n",
    "\n",
    "#creating production lookup dictionary\n",
    "lookup = {}\n",
    "for prod in grammar.productions():\n",
    "    if prod.rhs() in lookup:\n",
    "        lookup[prod.rhs()] += [prod.lhs()]\n",
    "    else:\n",
    "        lookup[prod.rhs()] = [prod.lhs()]\n",
    "    \n",
    "#filling diagonal\n",
    "for i in range(len(tokens)):\n",
    "    prods = grammar.productions(rhs=tokens[i])\n",
    "    table[i][i]= [x.lhs() for x in prods]\n",
    "\n",
    "#filling rest of table with cyk algorithm\n",
    "for i in range(2,size+1):\n",
    "    for j in range(size-i+1):\n",
    "        \n",
    "        for k in range(j,j+i-1):\n",
    "            \n",
    "            nt1, nt2 = table[j][k], table[k+1][j+i-1]\n",
    "            currentNts = []\n",
    "            \n",
    "            if nt1 and nt2:\n",
    "                for p1 in nt1:\n",
    "                    for p2 in nt2:\n",
    "                        \n",
    "                        if (p1,p2) in lookup:\n",
    "                            currentNts.extend(lookup[(p1,p2)])\n",
    "            table[j][j+i-1] += currentNts\n",
    "            \n",
    "IPython.display.display(HTML(\n",
    "    '<table><tr>{}</tr></table>'.format(\n",
    "        '</tr><tr>'.join(\n",
    "            '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) for row in table)\n",
    "        )\n",
    " ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ea92ac44-3103-4712-b35c-73314ce40e31"
    }
   },
   "source": [
    "<h3>3.3 Applying above CYK algorithm to parse address with PCFG (Probabilistic CFG):</h3>\n",
    "<pre>Where a normal CFG parser gives us two parse trees for the address \"<b>Harold Washington Library Center , 400 S. State Street , Cindy Pritzker Auditorium , Chicago , IL , us , 60605</b>\" , a PCFG parser can give us the most probable parse, based on multiplying the probabilities of the rules necessary for the derivation of each parse. This makes for a more accurate natural language understander.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "505a9aaf-1994-4d2d-87a7-dd3ffaad2890"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>[(NM, 0.3), (X7, 1.0)]</td><td>[(NM, 0.12)]</td><td>[(NM, 0.048)]</td><td>[(NM, 0.019200000000000002)]</td><td>[(NM, 0.012800000000000004)]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[(S, 8.360755199999997e-08)]</td></tr><tr><td>[]</td><td>[(NM, 0.3), (X7, 1.0)]</td><td>[(NM, 0.12)]</td><td>[(NM, 0.048)]</td><td>[(NM, 0.03200000000000001)]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[(S, 2.090188799999999e-07)]</td></tr><tr><td>[]</td><td>[]</td><td>[(NM, 0.3), (X7, 1.0)]</td><td>[(NM, 0.12)]</td><td>[(NM, 0.08000000000000002)]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[(S, 5.225471999999998e-07)]</td></tr><tr><td>[]</td><td>[]</td><td>[]</td><td>[(NM, 0.3), (X7, 1.0)]</td><td>[(NM, 0.2)]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[(S, 1.3063679999999992e-06)]</td></tr><tr><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[(ADD2, 0.05), (N, 1.0)]</td><td>[(ADD1, 0.010000000000000002), (X9, 0.1), (ADD2, 0.004)]</td><td>[(ADD1, 0.009)]</td><td>[(ADD1, 0.0026999999999999997)]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[(X1, 7.257599999999997e-06)]</td></tr><tr><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[(DIR, 0.1)]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td></tr><tr><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[(ADD1, 0.1), (STREET1, 1.0), (ST, 0.3)]</td><td>[(ST, 0.09), (ADD1, 0.075)]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[(X1, 0.00020159999999999994)]</td></tr><tr><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[(ADD1, 0.1), (STREET1, 1.0), (ST, 0.3)]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[(X1, 0.0002688)]</td></tr><tr><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[(ADD2, 0.01), (STREET2, 1.0), (ST1, 0.4)]</td><td>[(ADD2, 0.016), (ST1, 0.24)]</td><td>[(ADD2, 0.0096), (ST1, 0.144)]</td><td>[]</td><td>[]</td><td>[]</td><td>[(X2, 0.0026879999999999994)]</td></tr><tr><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[(ADD2, 0.01), (STREET2, 1.0), (ST1, 0.4)]</td><td>[(ADD2, 0.016), (ST1, 0.24)]</td><td>[]</td><td>[]</td><td>[]</td><td>[(X2, 0.00448)]</td></tr><tr><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[(ADD2, 0.01), (STREET2, 1.0), (ST1, 0.4)]</td><td>[]</td><td>[]</td><td>[]</td><td>[(X2, 0.0028)]</td></tr><tr><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[(CITY, 1.0), (CT, 0.4)]</td><td>[]</td><td>[]</td><td>[(X3, 0.27999999999999997)]</td></tr><tr><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[(STATE, 1.0)]</td><td>[]</td><td>[(X4, 0.7)]</td></tr><tr><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[(COUNTRY, 0.7)]</td><td>[(X5, 0.7)]</td></tr><tr><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[]</td><td>[(Z, 1.0)]</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "adr1 = \"Harold Washington Library Center , 400 S. State Street , Cindy Pritzker Auditorium , Chicago , IL , us , 60605\"\n",
    "grammar1 = \\\n",
    "    nltk.PCFG.fromstring(\"\"\"\n",
    "S -> NM X1 [0.6] | NM X6 [0.4]\n",
    "X6 -> ADD1 X3 [1.0]\n",
    "X1 -> ADD1 X2 [1.0]\n",
    "X2 -> ADD2 X3 [1.0]\n",
    "X3 -> CT X4 [1.0]\n",
    "X4 -> STATE X5 [1.0]\n",
    "X5 -> COUNTRY Z [1.0]\n",
    "NM -> X7 NM [0.4] | X7 X8 [0.1] | X7 N [0.2] | 'NAME' [0.3]\n",
    "X7 -> 'NAME' [1.0]\n",
    "X8 -> N NM [1.0]\n",
    "ADD1 -> X9 ST [0.3] | ST STREET1 [0.25] | 'STREET1' [0.1] | N DIR [0.1] | X9 AVE [0.05] | AVENUE AVE [0.1]| 'AVENUE' [0.06]| N ST [0.04]\n",
    "X9 -> N DIR [1.0]\n",
    "ADD2 -> FL ST1 [0.1]| X11 F [0.033]| N F [0.067]| OTH F [0.1]| F X11 [0.1]| SU N [0.1]| SUI FL [0.1]| SUI X13 [0.05]| FL SUI [0.05]| DIR ST1 [0.02]| N X14 [0.04]| STREET2 ST1 [0.04]| 'STREET2' [0.01]| N DIR [0.04]| N ST1 [0.05]| N X15 [0.01]| ST1 N [0.02]|ST1 X16 [0.02]| 'NUM' [0.05]\n",
    "X16 -> DIR ST1 [1.0]\n",
    "X15 -> SS ST1 [1.0]\n",
    "X14 -> DIR ST1 [1.0]\n",
    "X13 -> FL ST1 [1.0]\n",
    "N -> 'NUM' [1.0]\n",
    "CITY -> 'CITY' [1.0]\n",
    "CT -> 'CITY' [0.4] | CITY CITY [0.6]\n",
    "STATE -> 'IL' [1.0]\n",
    "Z -> 'ZIP' [1.0]\n",
    "COUNTRY -> 'us' [0.7] | 'US' [0.3]\n",
    "DIR -> 'N.' [0.1]| 'S.'[0.1] | 'W.' [0.1] |'E.' [0.1] |'North' [0.05] |'South' [0.05] |'West' [0.05]|'East' [0.05]|'N' [0.05] |'S' [0.05]|'E' [0.05] |'W' [0.05]|'w.' [0.05]|'s.' [0.05] |'n.' [0.05] |'e.' [0.05]\n",
    "STREET1 -> 'STREET1' [1.0]\n",
    "ST -> STREET1 ST [0.3] | STREET1 N [0.2]| STREET1 X10 [0.2]| 'STREET1' [0.3]\n",
    "X10 -> N ST [1.0]\n",
    "AVE -> AVENUE AVE [0.6] | 'AVENUE' [0.4]\n",
    "AVENUE -> 'AVENUE' [1.0]\n",
    "STREET2 ->\t'STREET2' [1.0]\n",
    "ST1 -> STREET2 ST1 [0.6] | 'STREET2' [0.4]\n",
    "SUI -> SU N [1.0]\n",
    "FL -> X11 F [0.3] | N F [0.2] | OTH F [0.2] | F X11 [0.3]\n",
    "X11 -> N SS [1.0]\n",
    "OTH -> 'Top' [0.5] | 'Main' [0.5]\n",
    "F -> 'FLOOR' [1.0]\n",
    "SU -> 'SUITE' [1.0]\n",
    "SS -> 'SUP' [1.0]\n",
    "\"\"\")\n",
    "\n",
    "pattern = [(r'^(?!(?:^6[0-9]{4,4}$)$)\\d+','NUM'),(r'^(?!(?:^6[0-9]{4,4}$)|(\\(|\\)|IL|us|US|N\\.|W\\.|E\\.|S\\.|N|W|E|S|n\\.|w\\.|e\\.|s\\.|Ave|Ave\\.|ave|avenue|Avenue|AVENUE|ave\\.|West|North|East|,|South|Suite|suite|SUITE|Floor|Fl.|Fl|floor|nd|th)$).*','STREET1'),(r'(Suite|suite|SUITE)','SUITE'),(r'(nd|th)','SUP'),(r'(floor|Fl.|Fl|Floor)','FLOOR'),(r',','COM'),(r'\\(|\\)','BRAC'),(r'Ave|Ave.|ave|avenue|Avenue|AVENUE|ave.','AVENUE'),(r'^6[0-9]{4,4}$','ZIP')]\n",
    "tagger = nltk.RegexpTagger(pattern)\n",
    "    \n",
    "t = []\n",
    "f = 0\n",
    "p = 0\n",
    "start = 0\n",
    "end = 0\n",
    "for (y, x) in tagger.tag(nltk.word_tokenize(adr1)):\n",
    "    if x is not None and x != 'COM' and x != 'BRAC' and f == 0:\n",
    "        if x == 'STREET1':\n",
    "            x = 'NAME'\n",
    "        t.append(x)\n",
    "    elif x != None and x != 'COM' and x != 'BRAC' and f == 1:\n",
    "        t.append(x)\n",
    "    elif x != None and x != 'COM' and x != 'BRAC' and f == 2:\n",
    "        if x == 'STREET1':\n",
    "            x = 'STREET2'\n",
    "        t.append(x)\n",
    "    elif x != None and x != 'COM' and x != 'BRAC' and f == 3:\n",
    "        if x == 'STREET1':\n",
    "            x = 'CITY'\n",
    "        t.append(x)\n",
    "    elif x != None and x != 'COM' and x != 'BRAC' and f == 6:\n",
    "        t.append(x)\n",
    "    elif x == 'COM':\n",
    "        f += 1\n",
    "    elif x == None:\n",
    "        t.append(y)\n",
    "\n",
    "\n",
    "if 'AVENUE' in t:\n",
    "    p = 1\n",
    "\n",
    "if p == 1:\n",
    "    for (index, item) in enumerate(t):\n",
    "        if 'STREET1' in item:\n",
    "            start = index\n",
    "            break\n",
    "    for (index, item) in enumerate(t):\n",
    "        if 'AVENUE' in item:\n",
    "            end = index\n",
    "            break\n",
    "    for i in range(start, end):\n",
    "        t[i] = 'AVENUE'\n",
    "            \n",
    "tokens = t\n",
    "grammar = grammar1\n",
    "    \n",
    "#creating table\n",
    "size = len(tokens)\n",
    "table = [ [[] for i in range(size)] for i in range(size) ]\n",
    "\n",
    "#creating production lookup dictionary\n",
    "lookup = {}\n",
    "for prod in grammar.productions():\n",
    "    if prod.rhs() in lookup:\n",
    "        lookup[prod.rhs()] += [(prod.lhs(),prod.prob())]\n",
    "    else:\n",
    "        lookup[prod.rhs()] = [(prod.lhs(),prod.prob())]\n",
    "\n",
    "#filling diagonal\n",
    "for i in range(len(tokens)):\n",
    "    prods = grammar.productions(rhs=tokens[i])\n",
    "    table[i][i]= [(x.lhs(),x.prob()) for x in prods]\n",
    "\n",
    "#filling rest of table with cyk algorithm\n",
    "for i in range(2,size+1):\n",
    "    for j in range(size-i+1):\n",
    "        \n",
    "        for k in range(j,j+i-1):\n",
    "            \n",
    "            nt1, nt2 = table[j][k], table[k+1][j+i-1]\n",
    "            currentNts = []\n",
    "            \n",
    "            if nt1 and nt2:\n",
    "                for p1 in nt1:\n",
    "                    for p2 in nt2:                  \n",
    "                        if (p1[0],p2[0]) in lookup:\n",
    "                            for o in lookup[(p1[0],p2[0])]:\n",
    "                                currentNts.append((o[0],p1[1]*p2[1]*o[1]))\n",
    "            table[j][j+i-1] += currentNts\n",
    "\n",
    "IPython.display.display(HTML(\n",
    "    '<table><tr>{}</tr></table>'.format(\n",
    "        '</tr><tr>'.join(\n",
    "            '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) for row in table)\n",
    "        )\n",
    " ))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
